{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "1c10b768-f5b4-43bc-a785-99077422ce78",
      "metadata": {
        "id": "1c10b768-f5b4-43bc-a785-99077422ce78"
      },
      "source": [
        "# Lesson 3: Chatbot Example"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "85d4fedc-4b90-4754-9f2d-fd3cfa321a14",
      "metadata": {
        "id": "85d4fedc-4b90-4754-9f2d-fd3cfa321a14"
      },
      "source": [
        "In this lesson, you will familiarize yourself with the chatbot example you will work on during this course. The example includes the tool definitions and execution, as well as the chatbot code. Make sure to interact with the chatbot at the end of this notebook."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install arxiv\n",
        "!pip install anthropic\n",
        "!pip install python-dotenv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CCztoewzTjQu",
        "outputId": "0e77c41f-a494-496b-ff39-19d7f58bc4b3"
      },
      "id": "CCztoewzTjQu",
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: arxiv in /usr/local/lib/python3.11/dist-packages (2.2.0)\n",
            "Requirement already satisfied: feedparser~=6.0.10 in /usr/local/lib/python3.11/dist-packages (from arxiv) (6.0.11)\n",
            "Requirement already satisfied: requests~=2.32.0 in /usr/local/lib/python3.11/dist-packages (from arxiv) (2.32.3)\n",
            "Requirement already satisfied: sgmllib3k in /usr/local/lib/python3.11/dist-packages (from feedparser~=6.0.10->arxiv) (1.0.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests~=2.32.0->arxiv) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests~=2.32.0->arxiv) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests~=2.32.0->arxiv) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests~=2.32.0->arxiv) (2025.6.15)\n",
            "Requirement already satisfied: anthropic in /usr/local/lib/python3.11/dist-packages (0.54.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from anthropic) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from anthropic) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.25.0 in /usr/local/lib/python3.11/dist-packages (from anthropic) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from anthropic) (0.10.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from anthropic) (2.11.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from anthropic) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.10 in /usr/local/lib/python3.11/dist-packages (from anthropic) (4.14.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->anthropic) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.25.0->anthropic) (2025.6.15)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.25.0->anthropic) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.25.0->anthropic) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->anthropic) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->anthropic) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->anthropic) (0.4.1)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.11/dist-packages (1.1.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e0ed96ba-5ade-4af4-9096-406ce48d5cf2",
      "metadata": {
        "id": "e0ed96ba-5ade-4af4-9096-406ce48d5cf2"
      },
      "source": [
        "## Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "dd6bd1d4-f652-45d1-9efa-155a2cc01713",
      "metadata": {
        "id": "dd6bd1d4-f652-45d1-9efa-155a2cc01713"
      },
      "outputs": [],
      "source": [
        "import arxiv\n",
        "import json\n",
        "import os\n",
        "from typing import List\n",
        "from dotenv import load_dotenv\n",
        "import anthropic\n",
        "import openai"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f20f163a-87af-4e0c-87ed-1624c150c572",
      "metadata": {
        "id": "f20f163a-87af-4e0c-87ed-1624c150c572"
      },
      "source": [
        "## Tool Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "549a7f46-74b3-4a1d-b084-055c99e3c318",
      "metadata": {
        "id": "549a7f46-74b3-4a1d-b084-055c99e3c318"
      },
      "outputs": [],
      "source": [
        "PAPER_DIR = \"papers\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9e43905e-56f3-404c-a322-f038055e9b1c",
      "metadata": {
        "id": "9e43905e-56f3-404c-a322-f038055e9b1c"
      },
      "source": [
        "The first tool searches for relevant arXiv papers based on a topic and stores the papers' info in a JSON file (title, authors, summary, paper url and the publication date). The JSON files are organized by topics in the `papers` directory. The tool does not download the papers.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "886633b8-ce67-4343-822d-cc3f98f953fa",
      "metadata": {
        "id": "886633b8-ce67-4343-822d-cc3f98f953fa"
      },
      "outputs": [],
      "source": [
        "def search_papers(topic: str, max_results: int = 5) -> List[str]:\n",
        "    \"\"\"\n",
        "    Search for papers on arXiv based on a topic and store their information.\n",
        "\n",
        "    Args:\n",
        "        topic: The topic to search for\n",
        "        max_results: Maximum number of results to retrieve (default: 5)\n",
        "\n",
        "    Returns:\n",
        "        List of paper IDs found in the search\n",
        "    \"\"\"\n",
        "\n",
        "    # Use arxiv to find the papers\n",
        "    client = arxiv.Client()\n",
        "\n",
        "    # Search for the most relevant articles matching the queried topic\n",
        "    search = arxiv.Search(\n",
        "        query = topic,\n",
        "        max_results = max_results,\n",
        "        sort_by = arxiv.SortCriterion.Relevance\n",
        "    )\n",
        "\n",
        "    papers = client.results(search)\n",
        "\n",
        "    # Create directory for this topic\n",
        "    path = os.path.join(PAPER_DIR, topic.lower().replace(\" \", \"_\"))\n",
        "    os.makedirs(path, exist_ok=True)\n",
        "\n",
        "    file_path = os.path.join(path, \"papers_info.json\")\n",
        "\n",
        "    # Try to load existing papers info\n",
        "    try:\n",
        "        with open(file_path, \"r\") as json_file:\n",
        "            papers_info = json.load(json_file)\n",
        "    except (FileNotFoundError, json.JSONDecodeError):\n",
        "        papers_info = {}\n",
        "\n",
        "    # Process each paper and add to papers_info\n",
        "    paper_ids = []\n",
        "    for paper in papers:\n",
        "        paper_ids.append(paper.get_short_id())\n",
        "        paper_info = {\n",
        "            'title': paper.title,\n",
        "            'authors': [author.name for author in paper.authors],\n",
        "            'summary': paper.summary,\n",
        "            'pdf_url': paper.pdf_url,\n",
        "            'published': str(paper.published.date())\n",
        "        }\n",
        "        papers_info[paper.get_short_id()] = paper_info\n",
        "\n",
        "    # Save updated papers_info to json file\n",
        "    with open(file_path, \"w\") as json_file:\n",
        "        json.dump(papers_info, json_file, indent=2)\n",
        "\n",
        "    print(f\"Results are saved in: {file_path}\")\n",
        "\n",
        "    return paper_ids"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "d20ee17a-afe6-438a-95b1-6e87742c7fac",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d20ee17a-afe6-438a-95b1-6e87742c7fac",
        "outputId": "1d4ef771-cd11-47fe-8a9c-5d4f7c1d953c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results are saved in: papers/computers/papers_info.json\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['1310.7911v2',\n",
              " 'math/9711204v1',\n",
              " '2208.00733v1',\n",
              " '2504.07020v1',\n",
              " '2403.03925v1']"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "search_papers(\"computers\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dfb83565-69af-47f3-9ba3-a96965cff7df",
      "metadata": {
        "id": "dfb83565-69af-47f3-9ba3-a96965cff7df"
      },
      "source": [
        "The second tool looks for information about a specific paper across all topic directories inside the `papers` directory."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "df9b1997-81cd-447d-9665-1cb72d93bb9a",
      "metadata": {
        "id": "df9b1997-81cd-447d-9665-1cb72d93bb9a"
      },
      "outputs": [],
      "source": [
        "def extract_info(paper_id: str) -> str:\n",
        "    \"\"\"\n",
        "    Search for information about a specific paper across all topic directories.\n",
        "\n",
        "    Args:\n",
        "        paper_id: The ID of the paper to look for\n",
        "\n",
        "    Returns:\n",
        "        JSON string with paper information if found, error message if not found\n",
        "    \"\"\"\n",
        "\n",
        "    for item in os.listdir(PAPER_DIR):\n",
        "        item_path = os.path.join(PAPER_DIR, item)\n",
        "        if os.path.isdir(item_path):\n",
        "            file_path = os.path.join(item_path, \"papers_info.json\")\n",
        "            if os.path.isfile(file_path):\n",
        "                try:\n",
        "                    with open(file_path, \"r\") as json_file:\n",
        "                        papers_info = json.load(json_file)\n",
        "                        if paper_id in papers_info:\n",
        "                            return json.dumps(papers_info[paper_id], indent=2)\n",
        "                except (FileNotFoundError, json.JSONDecodeError) as e:\n",
        "                    print(f\"Error reading {file_path}: {str(e)}\")\n",
        "                    continue\n",
        "\n",
        "    return f\"There's no saved information related to paper {paper_id}.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "0ebe0de7-8f07-4e08-a670-7b371fc3d2d9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "0ebe0de7-8f07-4e08-a670-7b371fc3d2d9",
        "outputId": "c4e885fb-147d-46e3-e626-2b4883a64d33"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'{\\n  \"title\": \"Compact manifolds with computable boundaries\",\\n  \"authors\": [\\n    \"Zvonko Iljazovic\"\\n  ],\\n  \"summary\": \"We investigate conditions under which a co-computably enumerable closed set\\\\nin a computable metric space is computable and prove that in each locally\\\\ncomputable computable metric space each co-computably enumerable compact\\\\nmanifold with computable boundary is computable. In fact, we examine the notion\\\\nof a semi-computable compact set and we prove a more general result: in any\\\\ncomputable metric space each semi-computable compact manifold with computable\\\\nboundary is computable. In particular, each semi-computable compact\\\\n(boundaryless) manifold is computable.\",\\n  \"pdf_url\": \"http://arxiv.org/pdf/1310.7911v2\",\\n  \"published\": \"2013-10-29\"\\n}'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "extract_info('1310.7911v2')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b5ea3013-e690-4bc8-8622-27b4d42d61e4",
      "metadata": {
        "id": "b5ea3013-e690-4bc8-8622-27b4d42d61e4"
      },
      "source": [
        "## Tool Schema"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7c7d2260-452d-472a-b56e-326479cb18c9",
      "metadata": {
        "id": "7c7d2260-452d-472a-b56e-326479cb18c9"
      },
      "source": [
        "Here are the schema of each tool which you will provide to the LLM."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "e5bdea5f-e93a-4018-8c13-00d5ee10c0b7",
      "metadata": {
        "id": "e5bdea5f-e93a-4018-8c13-00d5ee10c0b7"
      },
      "outputs": [],
      "source": [
        "tools = [\n",
        "    {\n",
        "        \"type\": \"function\",\n",
        "        \"function\": {\n",
        "            \"name\": \"search_papers\",\n",
        "            \"description\": \"REQUIRED: Use this function to search for academic papers on arXiv. Call this whenever the user asks about papers, research, or wants to find information on any topic.\",\n",
        "            \"parameters\": {\n",
        "                \"type\": \"object\",\n",
        "                \"properties\": {\n",
        "                    \"topic\": {\n",
        "                        \"type\": \"string\",\n",
        "                        \"description\": \"The research topic to search for (e.g., 'machine learning', 'quantum computing')\"\n",
        "                    },\n",
        "                    \"max_results\": {\n",
        "                        \"type\": \"integer\",\n",
        "                        \"description\": \"Number of papers to retrieve (default: 5, max: 20)\",\n",
        "                        \"minimum\": 1,\n",
        "                        \"maximum\": 20,\n",
        "                        \"default\": 5\n",
        "                    }\n",
        "                },\n",
        "                \"required\": [\"topic\"],\n",
        "                \"additionalProperties\": False\n",
        "            }\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"type\": \"function\",\n",
        "        \"function\": {\n",
        "            \"name\": \"extract_info\",\n",
        "            \"description\": \"REQUIRED: Use this function to get detailed information about a specific paper using its ID. Call this when user asks about a specific paper.\",\n",
        "            \"parameters\": {\n",
        "                \"type\": \"object\",\n",
        "                \"properties\": {\n",
        "                    \"paper_id\": {\n",
        "                        \"type\": \"string\",\n",
        "                        \"description\": \"The arXiv paper ID (e.g., '2301.12345', '1234.5678v1')\"\n",
        "                    }\n",
        "                },\n",
        "                \"required\": [\"paper_id\"],\n",
        "                \"additionalProperties\": False\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ec668d24-1559-41b7-bc8a-e2dca77dfaf2",
      "metadata": {
        "id": "ec668d24-1559-41b7-bc8a-e2dca77dfaf2"
      },
      "source": [
        "## Tool Mapping"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c728c1ec-36b1-48b4-9f85-622464ac79f4",
      "metadata": {
        "id": "c728c1ec-36b1-48b4-9f85-622464ac79f4"
      },
      "source": [
        "This code handles tool mapping and execution."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "c90790c0-efc4-4068-9c00-d2592d80bc30",
      "metadata": {
        "id": "c90790c0-efc4-4068-9c00-d2592d80bc30"
      },
      "outputs": [],
      "source": [
        "mapping_tool_function = {\n",
        "    \"search_papers\": search_papers,\n",
        "    \"extract_info\": extract_info\n",
        "}\n",
        "\n",
        "def execute_tool(tool_name, tool_args):\n",
        "    result = mapping_tool_function[tool_name](**tool_args)\n",
        "    if result is None:\n",
        "        result = \"The operation completed but didn't return any results.\"\n",
        "    elif isinstance(result, list):\n",
        "        result = ', '.join(result)\n",
        "    elif isinstance(result, dict):\n",
        "        result = json.dumps(result, indent=2)\n",
        "    else:\n",
        "        result = str(result)\n",
        "    return result\n",
        "\n",
        "# === SYSTEM PROMPT PARA FORZAR USO DE HERRAMIENTAS ===\n",
        "SYSTEM_PROMPT = \"\"\"You are an arXiv research assistant. You MUST use the provided tools for ALL paper-related queries.\n",
        "\n",
        "MANDATORY RULES:\n",
        "1. If user asks about papers, research, or any academic topic -> ALWAYS call search_papers()\n",
        "2. If user mentions a paper ID -> ALWAYS call extract_info()\n",
        "3. If user asks \"search for papers on X\" -> ALWAYS call search_papers() with topic \"X\"\n",
        "4. If user asks about a specific paper -> ALWAYS call extract_info()\n",
        "\n",
        "NEVER respond with general knowledge about papers or research topics. ALWAYS use the tools first.\n",
        "\n",
        "Examples that REQUIRE tool use:\n",
        "- \"Find papers on machine learning\" -> search_papers(topic=\"machine learning\")\n",
        "- \"Search for 3 papers about quantum computing\" -> search_papers(topic=\"quantum computing\", max_results=3)\n",
        "- \"Tell me about paper 2301.12345\" -> extract_info(paper_id=\"2301.12345\")\n",
        "- \"What papers are there on LLM interpretability?\" -> search_papers(topic=\"LLM interpretability\")\n",
        "\n",
        "You are an assistant that searches arXiv papers. Use your tools for EVERY paper-related query.\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4d8fc4d3-58ac-482c-8bbd-bccd6ef9fc31",
      "metadata": {
        "id": "4d8fc4d3-58ac-482c-8bbd-bccd6ef9fc31"
      },
      "source": [
        "## Chatbot Code"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e9ba0fad-b0e4-4415-a431-341e9ca85087",
      "metadata": {
        "id": "e9ba0fad-b0e4-4415-a431-341e9ca85087"
      },
      "source": [
        "The chatbot handles the user's queries one by one, but it does not persist memory across the queries."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "fe662400-8506-464e-a3da-75a3d8848bac",
      "metadata": {
        "id": "fe662400-8506-464e-a3da-75a3d8848bac"
      },
      "outputs": [],
      "source": [
        "client = openai.OpenAI(api_key=\"your-api-key\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "175586b4-acdf-4103-8039-134478a4f797",
      "metadata": {
        "id": "175586b4-acdf-4103-8039-134478a4f797"
      },
      "source": [
        "### Query Processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "12a896e0-3f56-417e-aa51-c61756048593",
      "metadata": {
        "id": "12a896e0-3f56-417e-aa51-c61756048593"
      },
      "outputs": [],
      "source": [
        "def process_query(query):\n",
        "    # Agregar system prompt explícito\n",
        "    messages = [\n",
        "        {'role': 'system', 'content': SYSTEM_PROMPT},\n",
        "        {'role': 'user', 'content': query}\n",
        "    ]\n",
        "\n",
        "    # Usar modelo que soporte function calling bien\n",
        "    response = client.chat.completions.create(\n",
        "        model='gpt-4o',  # Mejor para function calling\n",
        "        messages=messages,\n",
        "        tools=tools,\n",
        "        tool_choice='auto',  # Puede usar 'required' para forzar más\n",
        "        max_tokens=2024,\n",
        "        temperature=0.1  # Más determinístico\n",
        "    )\n",
        "\n",
        "    process_query = True\n",
        "    iteration = 0\n",
        "    max_iterations = 10  # Prevenir loops infinitos\n",
        "\n",
        "    while process_query and iteration < max_iterations:\n",
        "        iteration += 1\n",
        "        message = response.choices[0].message\n",
        "\n",
        "        print(f\"\\n--- Iteration {iteration} ---\")\n",
        "\n",
        "        # Si hay contenido de texto\n",
        "        if message.content:\n",
        "            print(f\"Assistant: {message.content}\")\n",
        "\n",
        "        # Si hay llamadas a herramientas\n",
        "        if message.tool_calls:\n",
        "            print(f\"🔧 Tool calls detected: {len(message.tool_calls)}\")\n",
        "\n",
        "            # Agregar el mensaje del asistente\n",
        "            messages.append({\n",
        "                \"role\": \"assistant\",\n",
        "                \"content\": message.content,\n",
        "                \"tool_calls\": message.tool_calls\n",
        "            })\n",
        "\n",
        "            # Procesar cada herramienta\n",
        "            for tool_call in message.tool_calls:\n",
        "                tool_name = tool_call.function.name\n",
        "                try:\n",
        "                    tool_args = json.loads(tool_call.function.arguments)\n",
        "                except json.JSONDecodeError as e:\n",
        "                    print(f\"Error parsing tool arguments: {e}\")\n",
        "                    continue\n",
        "\n",
        "                tool_id = tool_call.id\n",
        "\n",
        "                print(f\"Calling {tool_name} with args: {tool_args}\")\n",
        "\n",
        "                try:\n",
        "                    result = execute_tool(tool_name, tool_args)\n",
        "                    print(f\"Tool result: {result[:200]}...\" if len(result) > 200 else f\"Tool result: {result}\")\n",
        "                except Exception as e:\n",
        "                    result = f\"Error executing tool: {str(e)}\"\n",
        "                    print(f\"Tool error: {result}\")\n",
        "\n",
        "                # Agregar resultado\n",
        "                messages.append({\n",
        "                    \"role\": \"tool\",\n",
        "                    \"tool_call_id\": tool_id,\n",
        "                    \"content\": result\n",
        "                })\n",
        "\n",
        "            # Nueva llamada con resultados\n",
        "            response = client.chat.completions.create(\n",
        "                model='gpt-4o',\n",
        "                messages=messages,\n",
        "                tools=tools,\n",
        "                tool_choice='auto',\n",
        "                max_tokens=2024,\n",
        "                temperature=0.1\n",
        "            )\n",
        "\n",
        "        else:\n",
        "            # No hay más herramientas, terminar\n",
        "            process_query = False\n",
        "            if not message.content:\n",
        "                print(\"No content received from assistant\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2921ee7f-d2be-464b-ab7b-8db2a3c13ba9",
      "metadata": {
        "id": "2921ee7f-d2be-464b-ab7b-8db2a3c13ba9"
      },
      "source": [
        "### Chat Loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "16979cdc-81e9-432b-ba7f-e810b52961e8",
      "metadata": {
        "id": "16979cdc-81e9-432b-ba7f-e810b52961e8"
      },
      "outputs": [],
      "source": [
        "def chat_loop():\n",
        "    print(\"OpenAI ArXiv Assistant (Fixed)\")\n",
        "    print(\"=\" * 50)\n",
        "    print(\"Examples:\")\n",
        "    print(\"• 'Search for 3 papers on machine learning'\")\n",
        "    print(\"• 'Find papers about quantum computing'\")\n",
        "    print(\"• 'Tell me about paper 2301.12345'\")\n",
        "    print(\"• Type 'quit' to exit\")\n",
        "    print(\"=\" * 50)\n",
        "\n",
        "    while True:\n",
        "        try:\n",
        "            query = input(\"\\nQuery: \").strip()\n",
        "            if query.lower() in ['quit', 'exit', 'q']:\n",
        "                print(\"Goodbye!\")\n",
        "                break\n",
        "\n",
        "            if not query:\n",
        "                print(\"Please enter a query.\")\n",
        "                continue\n",
        "\n",
        "            # Verificar si parece una consulta de papers\n",
        "            paper_keywords = ['paper', 'search', 'find', 'arxiv', 'research', 'study']\n",
        "            if not any(keyword in query.lower() for keyword in paper_keywords):\n",
        "                print(\"Tip: I'm designed to search papers. Try: 'Search for papers on [topic]'\")\n",
        "\n",
        "            print(f\"\\nProcessing: '{query}'\")\n",
        "            process_query(query)\n",
        "            print(\"\\n\" + \"─\" * 50)\n",
        "\n",
        "        except KeyboardInterrupt:\n",
        "            print(\"\\nGoodbye!\")\n",
        "            break\n",
        "        except Exception as e:\n",
        "            print(f\"\\nError: {str(e)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1cfaf254-f22a-4951-885e-1d21fbc41ff3",
      "metadata": {
        "id": "1cfaf254-f22a-4951-885e-1d21fbc41ff3"
      },
      "source": [
        "Feel free to interact with the chatbot. Here's an example query:\n",
        "\n",
        "- Search for 2 papers on \"LLM interpretability\"\n",
        "\n",
        "To access the `papers` folder: 1) click on the `File` option on the top menu of the notebook and 2) click on `Open` and then 3) click on `L3`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "id": "39676f70-1c72-4da3-8363-da281bd5a83e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "39676f70-1c72-4da3-8363-da281bd5a83e",
        "outputId": "d9139d0b-7611-48d2-fb11-eb9205f39d41"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔧 Testing tool registration...\n",
            "Number of tools: 2\n",
            "- search_papers: REQUIRED: Use this function to search for academic papers on arXiv. Call this whenever the user asks...\n",
            "- extract_info: REQUIRED: Use this function to get detailed information about a specific paper using its ID. Call th...\n",
            "🤖 OpenAI ArXiv Assistant (Fixed)\n",
            "==================================================\n",
            "Examples:\n",
            "• 'Search for 3 papers on machine learning'\n",
            "• 'Find papers about quantum computing'\n",
            "• 'Tell me about paper 2301.12345'\n",
            "• Type 'quit' to exit\n",
            "==================================================\n",
            "\n",
            "📝 Query: Search for 3 papers on machine learning\n",
            "\n",
            "🔍 Processing: 'Search for 3 papers on machine learning'\n",
            "\n",
            "--- Iteration 1 ---\n",
            "🔧 Tool calls detected: 1\n",
            "📞 Calling search_papers with args: {'topic': 'machine learning', 'max_results': 3}\n",
            "Results are saved in: papers/machine_learning/papers_info.json\n",
            "📋 Tool result: 1909.03550v1, 1811.04422v1, 1707.04849v1\n",
            "\n",
            "--- Iteration 2 ---\n",
            "🔧 Tool calls detected: 3\n",
            "📞 Calling extract_info with args: {'paper_id': '1909.03550v1'}\n",
            "📋 Tool result: {\n",
            "  \"title\": \"Lecture Notes: Optimization for Machine Learning\",\n",
            "  \"authors\": [\n",
            "    \"Elad Hazan\"\n",
            "  ],\n",
            "  \"summary\": \"Lecture notes on optimization for machine learning, derived from a course at\\nPrince...\n",
            "📞 Calling extract_info with args: {'paper_id': '1811.04422v1'}\n",
            "📋 Tool result: {\n",
            "  \"title\": \"An Optimal Control View of Adversarial Machine Learning\",\n",
            "  \"authors\": [\n",
            "    \"Xiaojin Zhu\"\n",
            "  ],\n",
            "  \"summary\": \"I describe an optimal control view of adversarial machine learning, where th...\n",
            "📞 Calling extract_info with args: {'paper_id': '1707.04849v1'}\n",
            "📋 Tool result: {\n",
            "  \"title\": \"Minimax deviation strategies for machine learning and recognition with short learning samples\",\n",
            "  \"authors\": [\n",
            "    \"Michail Schlesinger\",\n",
            "    \"Evgeniy Vodolazskiy\"\n",
            "  ],\n",
            "  \"summary\": \"The...\n",
            "\n",
            "--- Iteration 3 ---\n",
            "Assistant: Here are three papers on machine learning:\n",
            "\n",
            "1. **Lecture Notes: Optimization for Machine Learning**\n",
            "   - **Author:** Elad Hazan\n",
            "   - **Summary:** These lecture notes focus on optimization techniques for machine learning, derived from a course at Princeton University and tutorials given at MLSS, Buenos Aires, and Simons Foundation, Berkeley.\n",
            "   - [Read the paper](http://arxiv.org/pdf/1909.03550v1)\n",
            "   - **Published:** 2019-09-08\n",
            "\n",
            "2. **An Optimal Control View of Adversarial Machine Learning**\n",
            "   - **Author:** Xiaojin Zhu\n",
            "   - **Summary:** This paper presents an optimal control perspective on adversarial machine learning, where the machine learner is viewed as a dynamical system influenced by adversarial actions. It covers various types of adversarial machine learning, including test-item attacks and training-data poisoning.\n",
            "   - [Read the paper](http://arxiv.org/pdf/1811.04422v1)\n",
            "   - **Published:** 2018-11-11\n",
            "\n",
            "3. **Minimax Deviation Strategies for Machine Learning and Recognition with Short Learning Samples**\n",
            "   - **Authors:** Michail Schlesinger, Evgeniy Vodolazskiy\n",
            "   - **Summary:** The paper addresses the challenges of small learning samples in machine learning. It critiques maximum likelihood and minimax learning, introducing the concept of minimax deviation learning to overcome these issues.\n",
            "   - [Read the paper](http://arxiv.org/pdf/1707.04849v1)\n",
            "   - **Published:** 2017-07-16\n",
            "\n",
            "Feel free to explore these papers for more detailed insights!\n",
            "\n",
            "──────────────────────────────────────────────────\n",
            "\n",
            "📝 Query: Find me 5 papers on MRP systems and give me a summary of each one.\n",
            "\n",
            "🔍 Processing: 'Find me 5 papers on MRP systems and give me a summary of each one.'\n",
            "\n",
            "--- Iteration 1 ---\n",
            "🔧 Tool calls detected: 1\n",
            "📞 Calling search_papers with args: {'topic': 'MRP systems', 'max_results': 5}\n",
            "Results are saved in: papers/mrp_systems/papers_info.json\n",
            "📋 Tool result: 2503.01862v1, 2302.01983v2, 2106.00538v2, 2010.05710v1, 1510.01713v1\n",
            "\n",
            "--- Iteration 2 ---\n",
            "🔧 Tool calls detected: 5\n",
            "📞 Calling extract_info with args: {'paper_id': '2503.01862v1'}\n",
            "📋 Tool result: {\n",
            "  \"title\": \"Clearing function-based release date optimization in a multi-item multi-stage MRP planned production system in a rolling-horizon planning environment with multilevel BOM\",\n",
            "  \"authors\": [...\n",
            "📞 Calling extract_info with args: {'paper_id': '2302.01983v2'}\n",
            "📋 Tool result: {\n",
            "  \"title\": \"Hybrid path-lifting algorithm and Equivalence of Stability results for MRP-based control strategies\",\n",
            "  \"authors\": [\n",
            "    \"Lu\\u00eds Martins\",\n",
            "    \"Carlos Cardeira\",\n",
            "    \"Paulo Oliveira\"\n",
            "...\n",
            "📞 Calling extract_info with args: {'paper_id': '2106.00538v2'}\n",
            "📋 Tool result: {\n",
            "  \"title\": \"A Markov Reward Process-Based Approach to Spatial Interpolation\",\n",
            "  \"authors\": [\n",
            "    \"Laurens Arp\"\n",
            "  ],\n",
            "  \"summary\": \"The interpolation of spatial data can be of tremendous value in vari...\n",
            "📞 Calling extract_info with args: {'paper_id': '2010.05710v1'}\n",
            "📋 Tool result: {\n",
            "  \"title\": \"HUJI-KU at MRP~2020: Two Transition-based Neural Parsers\",\n",
            "  \"authors\": [\n",
            "    \"Ofir Arviv\",\n",
            "    \"Ruixiang Cui\",\n",
            "    \"Daniel Hershcovich\"\n",
            "  ],\n",
            "  \"summary\": \"This paper describes the HUJI-...\n",
            "📞 Calling extract_info with args: {'paper_id': '1510.01713v1'}\n",
            "📋 Tool result: {\n",
            "  \"title\": \"Chatter Avoidance in Delayed Feedback Attitude Control with MRP Shadow Set Switching\",\n",
            "  \"authors\": [\n",
            "    \"Ehsan Samiei\",\n",
            "    \"Eric A. Butcher\"\n",
            "  ],\n",
            "  \"summary\": \"The chattering response...\n",
            "\n",
            "--- Iteration 3 ---\n",
            "Assistant: Here are summaries of five papers on MRP systems:\n",
            "\n",
            "1. **Clearing function-based release date optimization in a multi-item multi-stage MRP planned production system in a rolling-horizon planning environment with multilevel BOM**\n",
            "   - **Authors**: Wolfgang Seiringer, Klaus Altendorfer, Reha Uzsoy\n",
            "   - **Summary**: This study integrates clearing function-based release planning into MRP systems to address the rigidity of traditional MRP in variable production environments. By replacing backward scheduling with a CF-based optimization model, the study examines its effects on costs, lead times, and performance in multi-item, multi-stage systems. The CF-based approach consistently outperforms traditional MRP, especially under high demand uncertainty and shop load, highlighting its potential to enhance planning efficiency.\n",
            "   - [Read more](http://arxiv.org/pdf/2503.01862v1)\n",
            "   - **Published**: 2025-02-24\n",
            "\n",
            "2. **Hybrid path-lifting algorithm and Equivalence of Stability results for MRP-based control strategies**\n",
            "   - **Authors**: Luís Martins, Carlos Cardeira, Paulo Oliveira\n",
            "   - **Summary**: This paper presents a hybrid dynamic path-lifting mechanism for extracting MRPs from attitude space, allowing for robust MRP-based feedback control while maintaining stability properties. The approach avoids the unwinding phenomenon and ensures robust global exponential stability in attitude space tracking dynamics.\n",
            "   - [Read more](http://arxiv.org/pdf/2302.01983v2)\n",
            "   - **Published**: 2023-02-03\n",
            "\n",
            "3. **A Markov Reward Process-Based Approach to Spatial Interpolation**\n",
            "   - **Author**: Laurens Arp\n",
            "   - **Summary**: This work proposes using Markov reward processes (MRPs) for spatial interpolation, addressing limitations of existing methods like kriging. The proposed MRP variants operate locally while accounting for global spatial relationships, showing competitive advantages in reducing interpolation errors across various datasets.\n",
            "   - [Read more](http://arxiv.org/pdf/2106.00538v2)\n",
            "   - **Published**: 2021-06-01\n",
            "\n",
            "4. **HUJI-KU at MRP~2020: Two Transition-based Neural Parsers**\n",
            "   - **Authors**: Ofir Arviv, Ruixiang Cui, Daniel Hershcovich\n",
            "   - **Summary**: This paper describes the HUJI-KU system for the MRP 2020 shared task, using transition-based parsers with BERT embeddings. The system was adapted to new MRP frameworks and languages, achieving 4th place in cross-framework and cross-lingual tracks.\n",
            "   - [Read more](http://arxiv.org/pdf/2010.05710v1)\n",
            "   - **Published**: 2020-10-12\n",
            "\n",
            "5. **Chatter Avoidance in Delayed Feedback Attitude Control with MRP Shadow Set Switching**\n",
            "   - **Authors**: Ehsan Samiei, Eric A. Butcher\n",
            "   - **Summary**: This study investigates the chattering response in MRP shadow set switching for spacecraft attitude control with delayed feedback. A hysteretic boundary layer switching rule is proposed to reduce or avoid chattering, demonstrated through simulations.\n",
            "   - [Read more](http://arxiv.org/pdf/1510.01713v1)\n",
            "   - **Published**: 2015-09-29\n",
            "\n",
            "These papers cover various aspects of MRP systems, from production planning to control strategies and spatial interpolation.\n",
            "\n",
            "──────────────────────────────────────────────────\n",
            "\n",
            "📝 Query: De que trata este paper: 2503.01862v1\n",
            "\n",
            "🔍 Processing: 'De que trata este paper: 2503.01862v1'\n",
            "\n",
            "--- Iteration 1 ---\n",
            "🔧 Tool calls detected: 1\n",
            "📞 Calling extract_info with args: {'paper_id': '2503.01862v1'}\n",
            "📋 Tool result: {\n",
            "  \"title\": \"Clearing function-based release date optimization in a multi-item multi-stage MRP planned production system in a rolling-horizon planning environment with multilevel BOM\",\n",
            "  \"authors\": [...\n",
            "\n",
            "--- Iteration 2 ---\n",
            "Assistant: El paper titulado \"Clearing function-based release date optimization in a multi-item multi-stage MRP planned production system in a rolling-horizon planning environment with multilevel BOM\" fue escrito por Wolfgang Seiringer, Klaus Altendorfer y Reha Uzsoy. Este estudio explora la integración de la planificación de liberación basada en funciones de limpieza (CF) en los sistemas de Planificación de Requerimientos de Materiales (MRP), centrándose en mitigar la rigidez inherente del MRP al manejar la variabilidad en los entornos de producción.\n",
            "\n",
            "El trabajo investiga el impacto de reemplazar el paso de programación hacia atrás del MRP con un modelo de optimización basado en CF sobre los costos generales, los tiempos de entrega y el rendimiento del sistema en sistemas de producción de múltiples artículos y múltiples etapas. Se realizaron experimentos computacionales en dos sistemas distintos - uno simple y otro complejo - bajo diferentes comportamientos de demanda y niveles de utilización.\n",
            "\n",
            "Los hallazgos revelan que la planificación de pedidos de liberación basada en CF supera consistentemente al MRP tradicional en la gestión de costos y variabilidad, especialmente en escenarios de mayor incertidumbre de demanda y carga de trabajo. Aunque el MRP demuestra estabilidad en escenarios menos complejos, su incapacidad para adaptarse dinámicamente a la variabilidad conduce a costos más altos en la mayoría de las condiciones. El análisis destaca el potencial de los métodos basados en CF para mejorar la eficiencia de la planificación en entornos de producción dinámicos, proporcionando una base para futuras investigaciones sobre la integración de restricciones de capacidad dentro del marco más amplio del MRP.\n",
            "\n",
            "Puedes leer el documento completo en [este enlace](http://arxiv.org/pdf/2503.01862v1).\n",
            "\n",
            "──────────────────────────────────────────────────\n",
            "\n",
            "📝 Query: search for papers on algebra\n",
            "\n",
            "🔍 Processing: 'search for papers on algebra'\n",
            "\n",
            "--- Iteration 1 ---\n",
            "🔧 Tool calls detected: 1\n",
            "📞 Calling search_papers with args: {'topic': 'algebra'}\n",
            "Results are saved in: papers/algebra/papers_info.json\n",
            "📋 Tool result: 1104.3954v1, math/0501518v2, 1012.2844v1, 1607.02068v1, math/0506093v1\n",
            "\n",
            "--- Iteration 2 ---\n",
            "Assistant: Here are some papers on algebra:\n",
            "\n",
            "1. **Title:** The Algebra of Knots\n",
            "   - **arXiv ID:** 1104.3954v1\n",
            "\n",
            "2. **Title:** A Survey of the Algebraic Theory of Semigroups\n",
            "   - **arXiv ID:** math/0501518v2\n",
            "\n",
            "3. **Title:** Algebraic Geometry over Groups I: Algebraic Varieties\n",
            "   - **arXiv ID:** 1012.2844v1\n",
            "\n",
            "4. **Title:** Algebraic Geometry and Statistical Learning Theory\n",
            "   - **arXiv ID:** 1607.02068v1\n",
            "\n",
            "5. **Title:** The Algebra of Logic\n",
            "   - **arXiv ID:** math/0506093v1\n",
            "\n",
            "If you need more information about any of these papers, feel free to ask!\n",
            "\n",
            "──────────────────────────────────────────────────\n",
            "\n",
            "📝 Query: Give me the url of this paper id: 1607.02068v1\n",
            "\n",
            "🔍 Processing: 'Give me the url of this paper id: 1607.02068v1'\n",
            "\n",
            "--- Iteration 1 ---\n",
            "🔧 Tool calls detected: 1\n",
            "📞 Calling extract_info with args: {'paper_id': '1607.02068v1'}\n",
            "📋 Tool result: {\n",
            "  \"title\": \"Deformation quantization of vertex Poisson algebras\",\n",
            "  \"authors\": [\n",
            "    \"Shintarou Yanagida\"\n",
            "  ],\n",
            "  \"summary\": \"We introduce dg Lie algebras controlling the deformations of vertex algeb...\n",
            "\n",
            "--- Iteration 2 ---\n",
            "Assistant: The URL for the paper titled \"Deformation quantization of vertex Poisson algebras\" is [http://arxiv.org/pdf/1607.02068v1](http://arxiv.org/pdf/1607.02068v1).\n",
            "\n",
            "──────────────────────────────────────────────────\n",
            "\n",
            "👋 Goodbye!\n"
          ]
        }
      ],
      "source": [
        "# Para debugging - ver si las tools se están registrando\n",
        "def test_tools():\n",
        "    print(\"🔧 Testing tool registration...\")\n",
        "    print(f\"Number of tools: {len(tools)}\")\n",
        "    for tool in tools:\n",
        "        print(f\"- {tool['function']['name']}: {tool['function']['description'][:100]}...\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    test_tools()\n",
        "    chat_loop()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "34df7890-4b4c-4ec9-b06f-abc8c4a290e8",
      "metadata": {
        "id": "34df7890-4b4c-4ec9-b06f-abc8c4a290e8"
      },
      "source": [
        "<p style=\"background-color:#f7fff8; padding:15px; border-width:3px; border-color:#e0f0e0; border-style:solid; border-radius:6px\"> 🚨\n",
        "&nbsp; <b>Different Run Results:</b> The output generated by AI chat models can vary with each execution due to their dynamic, probabilistic nature. Don't be surprised if your results differ from those shown in the video.</p>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fb34ee2d",
      "metadata": {
        "id": "fb34ee2d"
      },
      "source": [
        "<div style=\"background-color:#fff6ff; padding:13px; border-width:3px; border-color:#efe6ef; border-style:solid; border-radius:6px\">\n",
        "<p> 💻 &nbsp; <b> To Access the <code>requirements.txt</code> file or the <code>papers</code> folder: </b> 1) click on the <em>\"File\"</em> option on the top menu of the notebook and then 2) click on <em>\"Open\"</em> and finally 3) click on <em>\"L3\"</em>.\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "508916f3-8fa1-4e21-bfa7-081a810bc36c",
      "metadata": {
        "id": "508916f3-8fa1-4e21-bfa7-081a810bc36c"
      },
      "source": [
        "In the next lessons, you will take out the tool definitions to wrap them in an MCP server. Then you will create an MCP client inside the chatbot to make the chatbot MCP compatible.  "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d02d207b-e07d-49ff-bb03-7954aa86c167",
      "metadata": {
        "id": "d02d207b-e07d-49ff-bb03-7954aa86c167"
      },
      "source": [
        "## Resources\n",
        "\n",
        "[Guide on how to implement tool use](https://docs.anthropic.com/en/docs/build-with-claude/tool-use/overview#how-to-implement-tool-use)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "71e5135e-01c3-4632-9f83-a1e6dd811049",
      "metadata": {
        "id": "71e5135e-01c3-4632-9f83-a1e6dd811049"
      },
      "source": [
        "<div style=\"background-color:#fff6ff; padding:13px; border-width:3px; border-color:#efe6ef; border-style:solid; border-radius:6px\">\n",
        "\n",
        "\n",
        "<p> ⬇ &nbsp; <b>Download Notebooks:</b> 1) click on the <em>\"File\"</em> option on the top menu of the notebook and then 2) click on <em>\"Download as\"</em> and select <em>\"Notebook (.ipynb)\"</em>.</p>\n",
        "\n",
        "</div>"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.12"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}